import os

import cv2
import google.generativeai as genai
import numpy as np
import PIL.Image
import tensorflow as tf
from dotenv import load_dotenv
from tensorflow.keras.layers import Dense, Dropout, Flatten  # type: ignore
from tensorflow.keras.metrics import Precision, Recall  # type: ignore
from tensorflow.keras.models import Sequential  # type: ignore
from tensorflow.keras.optimizers import Adamax  # type: ignore
from tensorflow.keras.preprocessing import image  # type: ignore

# Load the environment variables
load_dotenv()

# Configure the Generative AI API
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# Create a directory to store the saliency maps
output_dir = "saliency_maps"
os.makedirs(output_dir, exist_ok=True)


# Define the labels for the brain tumor classes
def generate_explanation(img_path, model_prediction, confidence):

    prompt = f"""You are an expert neurologist. You are tasked with explaining a asaliency map of a brain tumor MRI scan.
    The saliency map was generated by a deep learning model that was trained to classify brain tumors
    as either glioma, meningiom, pituitary, or no tumor.

    The saliency map highlights the regions of the image that the machine learning model is focusing on th make the predictions/

    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.

    In your response:
     - Explain what regions of the brain the model is focusing on. based on the saliency map. refer to the regions highlighted
     in light cyan, those are the regions where the model is focusing on.
     - Explain possible reasons why the model made the prediction it did.
     - Don't mention enything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan'
     in your explanation.
     - Keep your explanation to 4 sentences max.

    Let's think step by step about this. Verify step by step.
    """

    img = PIL.Image.open(img_path)

    model = genai.GenerativeModel(model_name="gemini-1.5-flash")
    response = model.generate_content([prompt, img])

    return response.text


# Generate a saliency map for a brain tumor MRI scan
def generate_saliency_map(model, img, uploaded_file, img_array, class_index, img_size):
    with tf.GradientTape() as tape:
        img_tensor = tf.convert_to_tensor(img_array)
        tape.watch(img_tensor)
        predictions = model(img_tensor)
        target_class = predictions[:, class_index]

    gradients = tape.gradient(target_class, img_tensor)
    gradients = tf.math.abs(gradients)
    gradients = tf.reduce_max(gradients, axis=-1)
    gradients = gradients.numpy().squeeze()

    gradients = cv2.resize(gradients, img_size)

    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
    radius = min(center[0], center[1]) - 10
    y, x = np.ogrid[: gradients.shape[0], : gradients.shape[1]]
    mask = (x - center[0]) ** 2 + (y - center[1]) ** 2 <= radius**2

    gradients = gradients * mask

    brain_gradients = gradients[mask]

    if brain_gradients.max() > brain_gradients.min():
        brain_gradients = (brain_gradients - brain_gradients.min()) / (
            brain_gradients.max() - brain_gradients.min()
        )
    gradients[mask] = brain_gradients

    threshold = np.percentile(gradients[mask], 80)
    gradients[gradients < threshold] = 0

    gradient = cv2.GaussianBlur(gradients, (11, 11), 0)

    heatmap = cv2.applyColorMap(np.uint8(255 * gradient), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

    heatmap = cv2.resize(heatmap, img_size)

    original_img = image.img_to_array(img)
    superimposed_img = heatmap * 0.7 + original_img * 0.3
    superimposed_img = superimposed_img.astype(np.uint8)

    img_path = os.path.join(output_dir, uploaded_file.name)
    with open(img_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    saliency_map_path = f"saliency_maps/{uploaded_file.name}"

    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

    return superimposed_img


# Load the Xception model
def load_xception_model(model_path):
    img_size = (299, 299, 3)
    base_model = tf.keras.applications.Xception(
        include_top=False, weights="imagenet", input_shape=img_size, pooling="max"
    )

    model = Sequential(
        [
            base_model,
            Flatten(),
            Dropout(rate=0.3),
            Dense(128, activation="relu"),
            Dropout(rate=0.25),
            Dense(4, activation="softmax"),
        ]
    )

    model.build((None,) + img_size)

    model.compile(
        Adamax(learning_rate=0.001),
        loss="categorical_crossentropy",
        metrics=["accuracy", Precision(), Recall()],
    )

    model.load_weights(model_path)

    return model
